# Test YAML file for running the 'postprocessor' scanner plugin, for testing
# out point reweighting
#
# To test this out, first run:
# ./gambit -f largetest_multinest+ascii.yaml
# to generate output to be reweighted.
# Then run this file.
#
# Ben Farmer <benjamin.farmer@fysik.su.se>
# Feb 2015
#
 
#======== Input parameter declarations =======
Parameters: 
  # Prior type is "none" because postprocessor 'scanner' will read in old points
  NormalDist:
    mu:
      prior_type: none
    sigma:
      prior_type: none

#======== Prior setup ========
#Priors:
#  read_from_file_prior:
#    parameters: [NormalDist::mu, NormalDist::sigma]
#    prior_type: plugin
#    plugin: parameter_reader


#======== Output setup ========
Printer:
  #printer: ascii
  #options:
  #  output_file: "results.txt"
  #  buffer_length: 1
  # Output can be re-printed into a different format via the postprocessor
  printer: hdf5
  options:
    output_file: "results.hdf5"
    group: "/reweight_data"
    delete_file_on_restart: true
    # Current a special setting is required here to allow the postproccessing scanner to print to points in an erratic order.
    #postproccess_mode: true
 
#======== Scanner setup ========
Scanner:
  use_scanner: postprocess

  scanners:

    postprocess:
      plugin: postprocessor
      # 'purpose' name assigned to log-likelihood for this 'scan'
      loglike: LogLike2
      # If the purpose name above collides with an entry in the selected input file 
      # (e.g. an old likelihood from the original scan), should the old data be discarded?
      permit_discard_old_logLike: true
      # List of labels in old output to treat as likelihoods to be added to the newly computed LogLike.
      # It is assumed that these are stored as doubles. If they aren't, something unexpected may happen...
      add_to_loglike: [LogLike, LogLike]
      # List of labels in old output to treat as likelihoods to be subtracted from the newly computed LogLike.
      # (for example if you recompute a new likelihood component with a different tool, you may want to
      #  subtract the old component here)
      subtract_from_loglike: [LogLike, LogLike]
      # Note, there is no protection from adding then subtracting the same component, or from adding the same component twice etc.
      # More complicated arrangements of old + new likelihood components go beyond the goals of this scanner.
      # Use plotting tools for that kind of thing.

      # Set interval between progress report messages to stdout (0 for no messages, default 1000)
      #update_interval: 1000
      reader:
        # This determines what old output file is to be read and whose parameter points are to be used
        type: hdf5
        #type: ascii
        # Currently the asciiReader only works on one file, so they need to be combined before postprocessing. Just cat-ing them together should work.
        #info_filename: "runs/largetest_multinest+ascii/samples/results.txt_info_0"
        #data_filename: "runs/largetest_multinest+ascii/samples/results.txt_0"
        file: "runs/spartan_multinest_hdf5/samples/results.hdf5"
        group: "/"

#  objectives:
#
#    parameter_reader:
#      plugin: reweight_prior
 
                   
#======== Observables of interest ========
ObsLikes:
  - purpose:      LogLike2
    capability:   normaldist_loglike
    module:       ExampleBit_A
    type:         double

#======== Rule entries ========
Rules:
  # None required

#======== Logging setup ========
Logger:
  redirection:
    [Default]      : "default.log"
    [Utilities]    : "utils.log"
    [Utilities,Info] : "utils_info.log"
    [ExampleBit_A] : "ExampleBit_A.log"
    [Scanner]      : "Scanner.log"
    [Printers]     : "Printers.log"

#======== Generic Name/Value Section ========
KeyValues:

  default_output_path: "runs/postprocessor_test/"

  print_timing_data: false

  rng: ranlux48

  likelihood:
    model_invalid_for_lnlike_below: -1e6
