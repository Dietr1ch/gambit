%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a  template file for the LaTeX package SVJour3 width change file svepjc3.clo
% for Springer journal:
% The European Physical Journal C
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
%\begin{filecontents*}{example.eps}
%!PS-Adobe-3.0 EPSF-3.0
%%BoundingBox: 19 19 221 221
%%CreationDate: Mon Sep 29 1997
%%Creator: programmed by hand (JK)
%%EndComments
%gsave
%newpath
%  20 20 moveto
%  20 220 lineto
%  220 220 lineto
%  220 20 lineto
%closepath
%2 setlinewidth
%gsave
%  .4 setgray fill
%grestore
%stroke
%grestore
%\end{filecontents*}
%
\RequirePackage{fix-cm}
%
\documentclass[twocolumn,epjc3]{svjour3}  
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\RequirePackage{graphicx}
\RequirePackage{color}
%
% \RequirePackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
\RequirePackage{latexsym}
%\RequirePackage[numbers,sort&compress]{natbib}
%\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue,linkcolor=blue]{hyperref}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
\journalname{Eur. Phys. J. C}
%
\begin{document}

\title{DarkBit -- a Modular Tool and Interface to Compute Dark Matter Properties%\thanksref{t1}
}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

\titlerunning{DarkBit}        % if too long for running head

\author{Torsten Bringmann, Jan Conrad, Jonathan M.~Cornell, Lars A.~Dal, Joakim Edsj\"o, Miguel Pato, Antje Putze, Christopher Savage, Pat Scott, Christoph Weniger + XXX\thanksref{e1,addr1,addr2}
%        \and
%        Second Author\thanksref{e2,addr2,addr3} %etc.
}

\thankstext{e1}{e-mail: resistanceisfutile@gambit.com}

%\authorrunning{Short form of author list} % if too long for running head

\institute{First address \label{addr1}
           \and
           Second address \label{addr2}
%           \and
%           \emph{Present Address:} if needed\label{addr3}
}

\date{\today}


\newcommand{\DB}{\mbox{\sf DarkBit}}
\newcommand{\GB}{\mbox{\sf GAMBIT}}

\newcommand{\tb}[1]{{\color{green}\textbf{[TB: #1]}}}


\maketitle

\begin{abstract}

{\bf [TB]} The identity of dark matter remains one of the biggest open questions in fundamental 
science. A plethora of possible candidates exists, though, in terms of new elementary 
particles that are predicted in extensions of the standard model of particle physics. Here, 
we introduce  \DB, an advanced numerical framework to compute the properties of dark 
matter particles in such scenarios. While several numerical codes with a similar scope 
already exist, they all have their specific strengths and limitations. In this context, the main 
new feature and added value of \DB\ is its radically modular structure, which allows to 
easily set up new models and to interface to basically any existing code in a both flexible 
and efficient way. On top of that there are several genuinely new elements, including much 
more realistic likelihoods than typically implemented in publicly available codes. \DB\ is 
optimized to allow the inclusion of sophisticated dark matter observations in global scans of 
any type, especially with the new Global And Modular Beyond the Standard Model 
Inference Tool (\GB), but it is also a very powerful tool  as a standalone application.
Here we describe its main functionality as currently implemented, provide a guide to get 
started quickly, and show illustrative examples for results obtained with \DB. 
This includes a quantitative comparison between two of the major available codes 
({\sf DarkSUSY} and {\sf micrOMEGAs}), an analysis of gamma-rays from cascade 
decays, ... XXX 

%\keywords{First keyword \and Second keyword \and More}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction [TB/AP/XXX]}
\label{intro}

\begin{itemize}
\item intro to physics: DM and WIMPs; motivation, production + detection methods
\item outline scope of \DB; relations to backends \& genuinely new aspects
\item relation to \GB
\end{itemize}

\smallskip
{\color{red} !!! TO DO !!!}
\smallskip


This article is organized as follows. In Section \ref{phys} we  briefly introduce the general physics 
context and the main  observables to be calculated, before describing in Section \ref{code} the corresponding 
implementation details for the various modules of \DB. Validation tests and illustrative examples of typical
\DB\ usage are presented in Section \ref{examples}. We continue with an outlook on planned code expansions 
with future releases in Section \ref{out}, and conclude in Section \ref{conc}. In \ref{code_init} we provide a quick 
guide for how to install \DB\ and get started with a simple test example.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Physics framework}
\label{phys}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Relic density {\bf [JE]}}
\label{phys_rd}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Direct detection {\bf [CS]}}
\label{phys_dd}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Indirect detection {\bf [TB]}}
\label{phys_id}

The third traditional way of looking for DM is to test the particle hypothesis {\it in situ}, by 
identifying the (standard model) products that result from DM annihilation or decay
at places with large DM densities. {\it Locally}, the injection rate of a standard model 
particle type $f$, per volume and energy, is given by

\begin{equation}
\frac{d\mathcal{Q}(E_f,\mathbf{x})}{dE_f}= \frac1{N_\chi} \frac{\rho_\chi^2(\mathbf{x})}{m_\chi^2} \sum_i \left\langle \sigma_i v \frac{dN_i}{dE_f}\right\rangle\,.
\end{equation}
Here, $\sigma_i$ is the annihilation cross section into final state $i$,  $v$ the relative 
velocity of the DM particles, $\langle...\rangle$ denotes an ensemble average over 
velocities, and $dN_i/dE_f$ is the (differential) number of particles $f$ that result per
annihilation into final state $i$. The dark matter density is given by $\rho_\chi$  and its 
mass by $m_\chi$; $N_\chi$, finally, denotes a symmetry factor that depends on the 
nature of the DM particle, e.g.~$N_\chi=2$ (4) for Majorana (Dirac) fermions.
For {\it decaying} DM, one simply has to replace 
$\langle \sigma_i v\rangle \rho_\chi^2/N_f\to m_\chi \Gamma_i \rho_\chi$ in the above 
expression, where $\Gamma_i$ is the partial decay width.

The multiplicities are typically not significantly affected by the ensemble average, allowing 
to write $\langle \sigma_i v$ $ {dN_i}/{dE_f}\rangle=\langle \sigma_i v \rangle \, {dN_i}/{dE_f}$ 
(and correspondingly for the decaying case)
and therefore to tabulate $\left.{dN_i}/{dE_f}\right|_{v=0}$ for a pre-defined set of DM 
masses; interpolating between these tables rather than running event generators such as 
{\sf Pythia} \cite{pythia} for every model point constitutes a significant gain in performance. 
In extreme cases, the multiplicities thus implemented in different DM codes can differ 
substantially -- mostly due to being based on different (versions of) event 
generators, but also due to different ways of (or a lack of) including contributions from 
higher-order  processes. \DB\ offers a flexible and convenient way to choose the desired 
multiplicities and switch between them for detailed comparisons (see Section \ref{code_id} 
for more details).

\medskip


Propgation, difference of species ...

\medskip


$\to$ general physics \& concepts; specifics go to next two subsections 
(including descriptions of respective likelihood).
{\color{red} To be completed...}
\smallskip



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Indirect detection with gamma rays {\bf [CW]}}
\label{phys_ga}

In this section, we will describe the experimental data, approach and
likelihood functions that we use in \GB\ to account for the most relevant
limits from gamma-ray observations \tb{at the beginning, I would also add a brief description of the expected
signal (continuum vs spectral features, spatial distribution, etc.)}.  A description of the code can be found
below in section~\ref{code_id}.

\paragraph{Dwarf spheroidal galaxies with Fermi.}
Some of the most stringent and robust limits on the dark matter annihilation
cross-section come from the (non-)observation of gamma-ray emission from dwarf
spheroidal Galaxies (dSphs).  These are satellite galaxies of the Milky Way,
with masses between $XXX$--$YYY M_\odot$, and with mass-to-light ratios up to
$XXX M_\odot/L_\odot$.  Besides the 12 `classical dSphs' and a number of
ultrafaint dSphs are know, which were mostly found by SDSS.\footnote{Very
recently, a number of dSph candidates were identified using DES
data~\cite{123}.  However, spectral follow-up observations to
determine the dark matter content of these candidates (and to
confirm them as dSphs) are still pending in most cases.}  

The distribution of dark matter in dSphs relies on a Jeans analysis of the
kinematic of member stars.  This distribution can then be used to calculate the
$J$-value (see definition above) of the dSph.  Following
Ref.~\cite{FermiDwarfs}, we will model associated uncertainties as a log-normal
distribution in $J$.  The full likelihood function reads then
%
\begin{equation}
  \mathcal{L} = \prod_i P_{\rm dwarf} P_{\rm J}
\end{equation}
%

\paragraph{Galactic center with Fermi.}
Gamma-ray observations of the Galactic center with Fermi have identified an
extended excess emission at energies around 2 GeV, which remarkably well
resembles a signal from dark matter annihilation (a very plausible alternative
which recently gained observational support~\cite{123} is the
unresolved emission from a large number of milli-second pulsars).  Assuming
that \emph{all} of the excess emission from the inner Galaxy is due to dark
matter annihilation, a likelihood function that takes into account realistic
estimates for the systematics introduced by foreground subtraction was derived
in Ref.~\cite{123}.  The associated likelihood function for the excess energy
spectrum features errors that are correltaed in energy, and reads
\begin{equation}
  \mathcal{L} = ...
\end{equation}

The derivation of best-fit cross-sections for dark matter models hinges on the
dark matter content in the inner 2 kpc of our Galaxy.  Associated uncertainties
were derived in Ref.~\cite{123}, and are included in the likelihood function as
a log-normal distribution.

\paragraph{Gamma-ray line limits from HESS.}

The limits on gamma-ray lines obtained by the HESS satellite at energies above
500 GeV are included in an effective way.  We interpolate flux upper limits
presented in Ref.~\cite{123} (linearly in $\log m_\chi$ and $\log \Phi$).  The
likelihood function that underlies the presented one-sided limits is assumed to
be XYZ.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Indirect detection with neutrinos {\bf [PS/JE]}}
\label{phys_nu}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Module description}
\label{code}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{General code framework {\bf [CW]}}
\label{code_gen}

\tb{While this section must somehow introduce the \GB\ framework, it must also become  clear that \DB\ is a standalone. So this relation should be spelled out a bit more (e.g.~by adding short introductory and trailing paragraphs, containing an complete list of all (\DB\ !)backends that are included in the first release!?)...}

\GB\ is build around the idea that \emph{all} calculations that are required to
get from experimental data and model parameters to likelihood functions are
perfomed in \GB\ \emph{module functions}.  As the name suggests, these
functions are grouped into various modules.  Each module function is able to
calculate exactly one parameter, its \emph{capability}.  The \emph{type} of
this capability can be just about anything, from a simple integer to any
complex C++ structure that is required to carry the calculational result.
Examples for capabilities are model parameters, structures carrying particle
spectra or experimental data, and the values of likelihood fucntions.  Most
module functions will also have \emph{dependencies} on capabilities that were
calculated by other module functions.  These dependencies will be resolved at
run time, based on choices of the user for what particle physics model to
analyse, what observables to include etc.  In general, the dependency tree of
the subset of module functions that are used for a specific scan will form a
directed a-cyclic graph.  Details can be found in the main \GB\
paper~\cite{123}.

In many cases, the calculations of module functions will actually require
functionality of external independent codes, like DarkSUSY or MircOmegas.
These codes provide a lot of functionaility that can be often used beyond the
scope of these codes (examples are Boltzmann solvers, tabulated particle
yields, routines to calculate J-values etc).  These codes from the perspective
of \GB\ \emph{backends}.  They are coupled to \GB\ by compiling them as shared
libraries, which are loaded by \GB\ at runtime if the user configuration
requires this.  The interface to these backends is provided by convenient
\emph{frontends}, which specify the form and subset of functionaility of the
backend that is accessible by \GB.

The whole setup is illustrated in Fig.~\ref{cartoon_definitions}.

\begin{itemize}
  \item connection to \GB, introduce concept of backends, setup and
    initialization of particle models
  \item briefly describe which backends are used, and what they contribute 
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Relic density {\bf [JE/TB]}}
\label{code_rd}
\begin{itemize}
  \item two possibilities: $W_\mathrm{eff}$ directly from DS or built from
    process catalogue (as introduced below)
  \item...
\end{itemize}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Direct detection {\bf [CS]}}
\label{code_dd}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Indirect detection {\bf [CW/TB]}}
\label{code_id}

$\to$ general physics \& concepts; specifics go to next two subsections
\begin{itemize}
\item Describe process catalogue 
\item Different final states: "basic" 2-body vs. cascade {\bf [LD]} vs higher-order corrections
\item...
\end{itemize}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Indirect detection with gamma rays {\bf [CW]}}
\label{code_ga}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Indirect detection with neutrinos {\bf [PS]}}
\label{code_nu}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Validation and  Examples}
\label{examples}

In this Section we present a few selected  examples that illustrate scope and
potential applications of \DB. At the same time, these examples serve as validation
tests of the code.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Setting up an effective WIMP model {\bf [CW]}}

$\to$ Briefly describe what we did in Geilo, and maybe reproduce Fig.5 in 1204.3622

\smallskip
{\color{red} !!! TO DO !!!}
\smallskip


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Comparing {\sf DarkSUSY} and {\sf micrOMEGAs} {\bf [JE/JC]}}

\DB\ offers the unique possibility to easily compare different numerical codes for the computation of DM properties
in a well-defined and consistent way. Here, we focus for illustration on the most widely used packages, {\sf DarkSUSY} 
\cite{xxx} and {\sf micrOMEGAs} \cite{xxx}. We stress, however, that it is straightforward for users to 
perform similar comparisons for essentially any other numerical code, simply by adding it as a backend to \DB.

\medskip
$\to$ focus on relic density, DD couplings, maybe spectra

\smallskip
{\color{red} !!! TO DO !!!}
\smallskip



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Gamma-ray spectra from cascade decays {\bf [LD/MP]}}

One of the main new features of this first \DB\ release is a novel way of calculating the cosmic-ray spectra that result from 
cascade decays of the primary products of DM annihilation or decay. For illustration we focus here on gamma
rays as final states, and compare in some detail the spectra obtained with \DB\ with those from other codes
as well as analytical expectations.

\smallskip
{\color{red} !!! TO DO !!!}
\smallskip



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Benchmark points for DM models {\bf [all]}}

\subsubsection{MSSM}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip


\subsubsection{Scalar Singlet DM}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{more examples ?}
...
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Outlook {\bf [all]}}
\label{out}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions {\bf [all]} }
\label{conc}
\smallskip
{\color{red} !!! TO DO !!!}
\smallskip




\begin{acknowledgements}
...
\end{acknowledgements}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix
\label{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Getting started  {\bf [CW/XXX]}}
\label{code_init}

$\to$ Installation, how to run test example

\smallskip
{\color{red} !!! TO DO !!!}
\smallskip


% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{}   % name your BibTeX data base

% Non-BibTeX users please use
\begin{thebibliography}{}
%
% and use \bibitem to create references. Consult the Instructions
% for authors for reference list style.
%
\bibitem{RefJ}
% Format for Journal Reference
Author, Article title, Journal, Volume, page numbers (year)
% Format for books
\bibitem{RefB}
Author, Book title, page numbers. Publisher, place (year)
% etc
\end{thebibliography}

\end{document}
% end of file template.tex

